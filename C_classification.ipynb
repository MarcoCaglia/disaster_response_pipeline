{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import vectorization\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.multioutput import MultiOutputClassifier \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 31/31 [00:41<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = vectorization.Vectorizer('messages_info.db')\n",
    "\n",
    "X_train, X_test, y_train, y_test = vectorizer.fit(workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26216, 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.vstack([X_train, X_test])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 2248 nearest neighbors...\n",
      "[t-SNE] Indexed 26216 samples in 0.002s...\n",
      "[t-SNE] Computed neighbors for 26216 samples in 26.230s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 9000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 10000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 11000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 12000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 13000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 14000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 15000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 16000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 17000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 18000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 19000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 20000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 21000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 22000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 23000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 24000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 25000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 26000 / 26216\n",
      "[t-SNE] Computed conditional probabilities for sample 26216 / 26216\n",
      "[t-SNE] Mean sigma: 0.246758\n",
      "[t-SNE] Computed conditional probabilities in 21.667s\n",
      "[t-SNE] Iteration 50: error = 295.1047668, gradient norm = 0.0291774 (50 iterations in 79.444s)\n",
      "[t-SNE] Iteration 100: error = 295.1022644, gradient norm = 0.0262365 (50 iterations in 76.936s)\n",
      "[t-SNE] Iteration 150: error = 295.1014709, gradient norm = 0.0237991 (50 iterations in 75.629s)\n",
      "[t-SNE] Iteration 200: error = 295.1015015, gradient norm = 0.0222718 (50 iterations in 78.483s)\n",
      "[t-SNE] Iteration 250: error = 295.1024780, gradient norm = 0.0258849 (50 iterations in 78.372s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 295.102478\n",
      "[t-SNE] Iteration 300: error = 1.8389382, gradient norm = 0.0006969 (50 iterations in 64.482s)\n",
      "[t-SNE] Iteration 350: error = 1.7002966, gradient norm = 0.0001850 (50 iterations in 63.107s)\n",
      "[t-SNE] Iteration 400: error = 1.6645020, gradient norm = 0.0000863 (50 iterations in 63.148s)\n",
      "[t-SNE] Iteration 450: error = 1.6505798, gradient norm = 0.0000463 (50 iterations in 63.103s)\n",
      "[t-SNE] Iteration 500: error = 1.6433971, gradient norm = 0.0000332 (50 iterations in 68.381s)\n",
      "[t-SNE] Iteration 550: error = 1.6400938, gradient norm = 0.0000216 (50 iterations in 68.933s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-7f6df7c684af>\", line 8, in <module>\n",
      "    verbose=2).fit_transform(X_reduced)\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\site-packages\\sklearn\\manifold\\t_sne.py\", line 895, in fit_transform\n",
      "    embedding = self._fit(X)\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\site-packages\\sklearn\\manifold\\t_sne.py\", line 813, in _fit\n",
      "    skip_num_points=skip_num_points)\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\site-packages\\sklearn\\manifold\\t_sne.py\", line 864, in _tsne\n",
      "    **opt_args)\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\site-packages\\sklearn\\manifold\\t_sne.py\", line 357, in _gradient_descent\n",
      "    inc = update * grad < 0.0\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\cagli\\Anaconda3\\envs\\dashmote\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "X_reduced = PCA(n_components=50).fit_transform(X)\n",
    "visual = TSNE(n_components=2,\n",
    "              perplexity=X_reduced.shape[0]/y_train.shape[1],\n",
    "              learning_rate=500,\n",
    "              early_exaggeration=50,  ### Early exaggertaion or learning_rate are too high\n",
    "              n_iter=1500,\n",
    "              metric='cosine',\n",
    "              verbose=2).fit_transform(X_reduced)\n",
    "\n",
    "visual = pd.DataFrame(visual, columns=['x', 'y'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.scatterplot(x='x', y='y', data=visual, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing (Supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Logistic Regression', 'SVC', 'AdaBoost', 'GradientBoosting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = MultiOutputClassifier(LogisticRegression(solver='lbfgs', n_jobs=12))\n",
    "logreg_start = datetime.datetime.now()\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg_end = datetime.datetime.now()\n",
    "y_hat_logreg = logreg.predict(X_test)\n",
    "\n",
    "logreg_results = {\n",
    "    'Training Time': str(logreg_end-logreg_start),\n",
    "    'Average F1-Score': np.mean([f1_score(y_test.values[:, category], y_hat_logreg[:, category], average='weighted') for category in range(y_test.shape[1])])\n",
    "}\n",
    "logreg_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc = MultiOutputClassifier(SVC(gamma='scale'))\n",
    "svc_start = datetime.datetime.now()\n",
    "svc.fit(X_train, y_train)\n",
    "svc_end = datetime.datetime.now()\n",
    "y_hat_svc = svc.predict(X_test)\n",
    "\n",
    "svc_results = {\n",
    "    'Training Time': str(svc_end-svc_start),\n",
    "    'Average F1-Score': np.mean([f1_score(y_test.values[:, category], y_hat_svc[:, category], average='weighted') for category in range(y_test.shape[1])])\n",
    "}\n",
    "svc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = MultiOutputClassifier(AdaBoostClassifer())\n",
    "adaboost_start = datetime.datetime.now()\n",
    "adaboost.fit(X_train, y_train)\n",
    "adaboost_end = datetime.datetime.now()\n",
    "y_hat_adaboost = adaboost.predict(X_test)\n",
    "\n",
    "adaboost_results = {\n",
    "    'Training Time': str(adaboost_end-adaboost_start),\n",
    "    'Average F1-score': np.mean([f1_score(y_test.values[:, category], y_hat_adaboost[:, category], average='weighted') for category in range(y_test.shape[1])])\n",
    "}\n",
    "adaboost_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradboost = MultiOutputClassifier(GradientBoostingClassifier())\n",
    "gradboost_start = datetime.datetime.now()\n",
    "gradboost.fit(X_train, y_train)\n",
    "gradboost_end = datetime.datetime.now()\n",
    "y_hat_gradboost = gradboost.predict(X_train, y_train)\n",
    "\n",
    "gradboost_results = {\n",
    "    'Training Time': str(gradboost_end-gradboost_start),\n",
    "    'Average F1-Score': np.mean([f1_score(y_test.values[:, category], y_hat_gradboost[:, category], average='weighted') for category in range(y_test.shape[1])])\n",
    "}\n",
    "gradboost_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing (Unsupervised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test here:\n",
    "- KMeans\n",
    "- GMM \n",
    "\n",
    "With one cluster for each category in y_train\n",
    "\n",
    "Also test OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
