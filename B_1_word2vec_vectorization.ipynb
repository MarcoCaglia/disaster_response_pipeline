{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import pprint\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import gensim.models.word2vec as w2v\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('messages_info.db')\n",
    "query = 'SELECT * FROM data'\n",
    "data = pd.read_sql(query, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cagli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cagli\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('file:\\\\Users\\\\cagli\\\\AppData\\\\Roaming\\\\nltk_data\\\\tokenizers\\\\punkt\\\\english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26216/26216 [00:02<00:00, 9558.49it/s]\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = ''\n",
    "for string in tqdm(data.message.tolist()):\n",
    "    corpus_raw = corpus_raw + string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sentences = tokenizer.tokenize(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(string):\n",
    "    clean = re.sub('[^a-zA-Z]', ' ', string)\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15303/15303 [00:00<00:00, 61365.04it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for raw_sentence in tqdm(raw_sentences):\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15303/15303 [00:00<00:00, 2297753.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, the messages contain 622,622 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "token_count = sum([len(sentence) for sentence in tqdm(sentences)])\n",
    "print('In total, the messages contain {0:,} tokens'.format(token_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300\n",
    "min_word_count = 3\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "context_size = 7\n",
    "downsampling = 1e-3\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages2vec = w2v.Word2Vec(\n",
    "    sg=0,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages2vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ASKED', 0.21404433250427246),\n",
       " ('marginal', 0.19698795676231384),\n",
       " ('shoots', 0.19423317909240723),\n",
       " ('Guinand', 0.18869811296463013),\n",
       " ('heartbreaking', 0.18761038780212402),\n",
       " ('enforced', 0.1843990534543991),\n",
       " ('wards', 0.18439701199531555),\n",
       " ('send', 0.18113936483860016),\n",
       " ('woke', 0.17987456917762756),\n",
       " ('protest', 0.17786851525306702)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2vec.wv.most_similar('Weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 13347\n"
     ]
    }
   ],
   "source": [
    "print('Word2Vec vocabulary length:', len(messages2vec.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "alpha_steps = (messages2vec.alpha - messages2vec.min_alpha) / epochs\n",
    "\n",
    "for epoch in tqdm(range(1,epochs+1)):\n",
    "    messages2vec.train(sentences, total_examples=messages2vec.corpus_count, epochs=1)\n",
    "    messages2vec.alpha -= alpha_steps\n",
    "    assert messages2vec.alpha > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('depression', 0.9650245904922485),\n",
       " ('gusts', 0.9600605964660645),\n",
       " ('downpour', 0.9591271877288818),\n",
       " ('Zambia', 0.959057092666626),\n",
       " ('exceptionally', 0.9578821063041687),\n",
       " ('thunderstorm', 0.9563523530960083),\n",
       " ('sudden', 0.9556964635848999),\n",
       " ('smog', 0.9551289081573486),\n",
       " ('consequent', 0.9527643918991089),\n",
       " ('Typhoon', 0.9527196884155273)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages2vec.wv.most_similar('Weather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
